{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/diffusion-model/blob/main/DDPM/DDPM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K1lu-xkj_DbM"
      },
      "outputs": [],
      "source": [
        "from contextlib import contextmanager\n",
        "from copy import deepcopy\n",
        "import math\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torchvision.transforms import functional as TF\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9q4lPoJf0-ly"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bLGurZOw_KRH"
      },
      "outputs": [],
      "source": [
        "def get_alphas_sigmas(t):\n",
        "    \"\"\"\n",
        "    Returns the scaling factors for the clean image (alpha) and for the\n",
        "    noise (sigma), given a timestep.\n",
        "    \"\"\"\n",
        "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
        "\n",
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "files = glob.glob(\"./output/*.png\")\n",
        "\n",
        "for f in files:\n",
        "    os.remove(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwW2cWHzugrl"
      },
      "source": [
        "# Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuyTXC4x_O0C",
        "outputId": "73e39a27-e79f-436c-eabf-ba33b256640e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 200\n",
        "epoches = 50\n",
        "ema_decay = 0.999\n",
        "steps = 500\n",
        "eta = 1.\n",
        "\n",
        "guidance_scale = 2.\n",
        "\n",
        "tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_set = datasets.CIFAR10(root='data', train=True, download=True, transform=tf, target_transform=lambda x: x if x < 5 else -1)\n",
        "train_dl = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUGf43CtukEa"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ABRAZs-_EhQ"
      },
      "outputs": [],
      "source": [
        "# Define the model (a residual U-Net)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, main, skip=None):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(*main)\n",
        "        self.skip = skip if skip else nn.Identity()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input) + self.skip(input)\n",
        "\n",
        "\n",
        "class ResConvBlock(ResidualBlock):\n",
        "    def __init__(self, c_in, c_mid, c_out, is_last=False):\n",
        "        skip = None if c_in == c_out else nn.Conv2d(c_in, c_out, 1, bias=False)\n",
        "        super().__init__([\n",
        "            nn.Conv2d(c_in, c_mid, 3, padding=1),\n",
        "            nn.Dropout2d(0.1, inplace=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(c_mid, c_out, 3, padding=1),\n",
        "            nn.Dropout2d(0.1, inplace=True) if not is_last else nn.Identity(),\n",
        "            nn.ReLU(inplace=True) if not is_last else nn.Identity(),\n",
        "        ], skip)\n",
        "\n",
        "\n",
        "class SelfAttention2d(nn.Module):\n",
        "    def __init__(self, c_in, n_head=1, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        assert c_in % n_head == 0\n",
        "        self.norm = nn.GroupNorm(1, c_in)\n",
        "        self.n_head = n_head\n",
        "        self.qkv_proj = nn.Conv2d(c_in, c_in * 3, 1)\n",
        "        self.out_proj = nn.Conv2d(c_in, c_in, 1)\n",
        "        self.dropout = nn.Dropout2d(dropout_rate, inplace=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        n, c, h, w = input.shape\n",
        "        qkv = self.qkv_proj(self.norm(input))\n",
        "        qkv = qkv.view([n, self.n_head * 3, c // self.n_head, h * w]).transpose(2, 3)\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "        scale = k.shape[3]**-0.25\n",
        "        att = ((q * scale) @ (k.transpose(2, 3) * scale)).softmax(3)\n",
        "        y = (att @ v).transpose(2, 3).contiguous().view([n, c, h, w])\n",
        "        return input + self.dropout(self.out_proj(y))\n",
        "\n",
        "\n",
        "class SkipBlock(nn.Module):\n",
        "    def __init__(self, main, skip=None):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(*main)\n",
        "        self.skip = skip if skip else nn.Identity()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.cat([self.main(input), self.skip(input)], dim=1)\n",
        "\n",
        "\n",
        "class FourierFeatures(nn.Module):\n",
        "    def __init__(self, in_features, out_features, std=1.):\n",
        "        super().__init__()\n",
        "        assert out_features % 2 == 0\n",
        "        self.weight = nn.Parameter(torch.randn([out_features // 2, in_features]) * std)\n",
        "\n",
        "    def forward(self, input):\n",
        "        f = 2 * math.pi * input @ self.weight.T\n",
        "        return torch.cat([f.cos(), f.sin()], dim=-1)\n",
        "\n",
        "\n",
        "def expand_to_planes(input, shape):\n",
        "    return input[..., None, None].repeat([1, 1, shape[2], shape[3]])\n",
        "\n",
        "\n",
        "class Diffusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        c = 64  # The base channel count\n",
        "\n",
        "        self.timestep_embed = FourierFeatures(1, 16)\n",
        "        self.class_embed = nn.Embedding(11, 4)\n",
        "\n",
        "        self.net = nn.Sequential(   # 32x32\n",
        "            ResConvBlock(3 + 16 + 4, c, c),\n",
        "            ResConvBlock(c, c, c),\n",
        "            SkipBlock([\n",
        "                nn.AvgPool2d(2),  # 32x32 -> 16x16\n",
        "                ResConvBlock(c, c * 2, c * 2),\n",
        "                ResConvBlock(c * 2, c * 2, c * 2),\n",
        "                SkipBlock([\n",
        "                    nn.AvgPool2d(2),  # 16x16 -> 8x8\n",
        "                    ResConvBlock(c * 2, c * 4, c * 4),\n",
        "                    SelfAttention2d(c * 4, c * 4 // 64),\n",
        "                    ResConvBlock(c * 4, c * 4, c * 4),\n",
        "                    SelfAttention2d(c * 4, c * 4 // 64),\n",
        "                    SkipBlock([\n",
        "                        nn.AvgPool2d(2),  # 8x8 -> 4x4\n",
        "                        ResConvBlock(c * 4, c * 8, c * 8),\n",
        "                        SelfAttention2d(c * 8, c * 8 // 64),\n",
        "                        ResConvBlock(c * 8, c * 8, c * 8),\n",
        "                        SelfAttention2d(c * 8, c * 8 // 64),\n",
        "                        ResConvBlock(c * 8, c * 8, c * 8),\n",
        "                        SelfAttention2d(c * 8, c * 8 // 64),\n",
        "                        ResConvBlock(c * 8, c * 8, c * 4),\n",
        "                        SelfAttention2d(c * 4, c * 4 // 64),\n",
        "                        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                    ]),  # 4x4 -> 8x8\n",
        "                    ResConvBlock(c * 8, c * 4, c * 4),\n",
        "                    SelfAttention2d(c * 4, c * 4 // 64),\n",
        "                    ResConvBlock(c * 4, c * 4, c * 2),\n",
        "                    SelfAttention2d(c * 2, c * 2 // 64),\n",
        "                    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                ]),  # 8x8 -> 16x16\n",
        "                ResConvBlock(c * 4, c * 2, c * 2),\n",
        "                ResConvBlock(c * 2, c * 2, c),\n",
        "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "            ]),  # 16x16 -> 32x32\n",
        "            ResConvBlock(c * 2, c, c),\n",
        "            ResConvBlock(c, c, 3, is_last=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, input, t, cond):\n",
        "        timestep_embed = expand_to_planes(self.timestep_embed(t[:, None]), input.shape)\n",
        "        class_embed = expand_to_planes(self.class_embed(cond + 1), input.shape)\n",
        "        return self.net(torch.cat([input, class_embed, timestep_embed], dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7Tm8u5vJhJ6"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample(model, x, steps, eta, classes, guidance_scale=1.):\n",
        "    ts = x.new_ones([x.shape[0]])\n",
        "\n",
        "    # Create the noise schedule\n",
        "    t = torch.linspace(1, 0, steps + 1)[:-1]\n",
        "    alphas, sigmas = get_alphas_sigmas(t)\n",
        "\n",
        "    # The sampling loop\n",
        "    for i in trange(steps):\n",
        "\n",
        "        # Get the model output (v, the predicted velocity)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            x_in = torch.cat([x, x])\n",
        "            ts_in = torch.cat([ts, ts])\n",
        "            classes_in = torch.cat([-torch.ones_like(classes), classes])\n",
        "            v_uncond, v_cond = model(x_in, ts_in * t[i], classes_in).float().chunk(2)\n",
        "        v = v_uncond + guidance_scale * (v_cond - v_uncond)\n",
        "\n",
        "        # Predict the noise and the denoised image\n",
        "        pred = x * alphas[i] - v * sigmas[i]\n",
        "        eps = x * sigmas[i] + v * alphas[i]\n",
        "\n",
        "        # If we are not on the last timestep, compute the noisy image for the\n",
        "        # next timestep.\n",
        "        if i < steps - 1:\n",
        "            # If eta > 0, adjust the scaling factor for the predicted noise\n",
        "            # downward according to the amount of additional noise to add\n",
        "            ddim_sigma = eta * (sigmas[i + 1]**2 / sigmas[i]**2).sqrt() * \\\n",
        "                (1 - alphas[i]**2 / alphas[i + 1]**2).sqrt()\n",
        "            adjusted_sigma = (sigmas[i + 1]**2 - ddim_sigma**2).sqrt()\n",
        "\n",
        "            # Recombine the predicted noise and predicted denoised image in the\n",
        "            # correct proportions for the next step\n",
        "            x = pred * alphas[i + 1] + eps * adjusted_sigma\n",
        "\n",
        "            # Add the correct amount of fresh noise\n",
        "            if eta:\n",
        "                x += torch.randn_like(x) * ddim_sigma\n",
        "\n",
        "    # If we are on the last timestep, output the denoised image\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIwAe5GJupC3"
      },
      "source": [
        "# Train Stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYYFSglmJX2"
      },
      "outputs": [],
      "source": [
        "rng = torch.quasirandom.SobolEngine(1, scramble=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytcz0Jxgjrnw"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, train_dl, epochs, device, scaler):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for images, labels in tqdm(train_dl):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Generate random timesteps\n",
        "            t = rng.draw(labels.shape[0])[:, 0].to(device)\n",
        "\n",
        "            # Get alphas and sigmas\n",
        "            alphas, sigmas = get_alphas_sigmas(t)\n",
        "\n",
        "            # Apply noise model\n",
        "            alphas = alphas[:, None, None, None]\n",
        "            sigmas = sigmas[:, None, None, None]\n",
        "\n",
        "            noise = torch.randn_like(images)\n",
        "            noised_reals = images * alphas + noise * sigmas\n",
        "\n",
        "            # with t increase, alpha goes down and sigmas goes up\n",
        "            # which means with t increase, targets will closer to - img\n",
        "            targets = noise * alphas - images * sigmas\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(noised_reals, t, labels)\n",
        "                loss = F.mse_loss(output, targets)  # Example loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Loss = {loss.item()}\")\n",
        "        noise = torch.randn([10, 3, 32, 32], device=device)\n",
        "        fakes_classes = torch.arange(10, device=device)\n",
        "\n",
        "        fakes = sample(model, noise, steps, eta, fakes_classes, guidance_scale)\n",
        "        fakes = (fakes + 1) / 2\n",
        "        fakes = torch.clamp(fakes, min=0, max = 1)\n",
        "        save_image(fakes.data, './output/%03d_train.png' % epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7r2NUnavAKm"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtAefZ2FjiS2"
      },
      "outputs": [],
      "source": [
        "model = Diffusion().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSYF-8DekXGq"
      },
      "outputs": [],
      "source": [
        "train_model(model, optimizer, train_dl, epochs=epoches, device=device, scaler = scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BpX1b2KwtMu"
      },
      "outputs": [],
      "source": [
        "image = Image.open(\"./output/09_train.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohsXa-IgwzJw"
      },
      "outputs": [],
      "source": [
        "image = Image.open(\"./output/020_train.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6mSPm2GxFGI"
      },
      "outputs": [],
      "source": [
        "image = Image.open(\"./output/029_train.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(\"./output/039_train.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(\"./output/049_train.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPhlDCo9PcAqfsRRRupoZoK",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50bd88a9ae654fe292b08f400e6d1f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_859efea98d3f4c6d8b07e64319afaaf7",
            "placeholder": "​",
            "style": "IPY_MODEL_e3847efff8874fc592dc32312257c5ed",
            "value": " 20%"
          }
        },
        "6ed89076d05d41ecaf0b42e01f4eed19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859efea98d3f4c6d8b07e64319afaaf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ad67bd73814c13ac24d9f239f1f145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50bd88a9ae654fe292b08f400e6d1f22",
              "IPY_MODEL_b326bb577b024702be6e2b16c342d71a",
              "IPY_MODEL_a0de68306d5648dc9596e97ca5a83152"
            ],
            "layout": "IPY_MODEL_6ed89076d05d41ecaf0b42e01f4eed19"
          }
        },
        "9958edc7e4944f828bec9426d1e36060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b9e551fda4e45d19e5bcadefe00cd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0de68306d5648dc9596e97ca5a83152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9e551fda4e45d19e5bcadefe00cd3e",
            "placeholder": "​",
            "style": "IPY_MODEL_9958edc7e4944f828bec9426d1e36060",
            "value": " 9977/50000 [01:28&lt;04:57, 134.53it/s]"
          }
        },
        "b326bb577b024702be6e2b16c342d71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc601df7e81744509d433c25111cf333",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bef72b25bd744827ae397f5f18777bb7",
            "value": 9977
          }
        },
        "bef72b25bd744827ae397f5f18777bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc601df7e81744509d433c25111cf333": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3847efff8874fc592dc32312257c5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
